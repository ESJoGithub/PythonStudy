{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ESJoGithub/PythonStudy/blob/main/DeepLearning/MNIST/Keras_220921_MNIST_%EC%8B%A4%EC%8A%B502_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxtO2zTTtPq3",
        "outputId": "fbc89bfd-b763-441b-a090-bfd6a23b42d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive /mydrive"
      ],
      "metadata": {
        "id": "e2ZTrV_htIFl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /mydrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ry3cBStVU1",
        "outputId": "d68f6a1a-9b4f-4e4c-950f-d6255ff5e762"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir mnist"
      ],
      "metadata": {
        "id": "98FN5iLDtXqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adf7c08-8039-4c89-b92c-e30070e9ac13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘mnist’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __CNN Layer & Batch Size 키우기__\n",
        "---\n",
        "SGD, adam, rmsprop 각 optimizer별 batch_size를 변경해볼 것"
      ],
      "metadata": {
        "id": "19CLRpWxwL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Library Import**"
      ],
      "metadata": {
        "id": "9Tx44ggmYNsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import datasets, layers, models                \n",
        "from tensorflow import keras                         # to_categorical 함수\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UFco5dLCQBQF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_imgs, train_labels), (test_imgs, test_labels) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "rwcqMzdKTPwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67db5f40-ef0f-47d1-af95-4c4fdfdea6f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 데이터 확인 및 전처리**"
      ],
      "metadata": {
        "id": "vcIHfL7pYJps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = train_imgs/255.0\n",
        "test_imgs = test_imgs/255.0"
      ],
      "metadata": {
        "id": "w4IFaKuOYIfc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_imgs.shape)\n",
        "print(test_imgs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ujYrDMiRy1",
        "outputId": "d77782f5-f5e7-40a6-fd83-e90af65f9c57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = train_imgs.reshape((60000, 28, 28, 1))\n",
        "test_imgs = test_imgs.reshape((10000, 28, 28, 1))"
      ],
      "metadata": {
        "id": "5IGxhDfjiN7d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "id": "ouDs40X-n_uw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Batchsize 변경__\n",
        "\n",
        "---\n",
        "64 -> 124로 조정"
      ],
      "metadata": {
        "id": "NTqxfKdbYvVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __1. batch_size=128, 출력 직전층 activation='relu', optimizer='SGD'__ "
      ],
      "metadata": {
        "id": "CMdQEIi7gG_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "EtDrGU7LlR96"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = keras.Sequential([\n",
        "  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation = 'relu'),\n",
        "  layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "LSy5b6TEYmJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1aab3bf-f6e8-4aa9-b30a-67cc4dd3b29b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                73792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,114\n",
            "Trainable params: 167,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rIRHwKY3gm2w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('mnist/try02.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "hist_1 = model_1.fit(train_imgs, train_labels, epochs=100, batch_size=128, validation_split=0.2, callbacks=[es, mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmGRWjkknkZo",
        "outputId": "e437caf7-bcbb-419f-9b1c-751359916ba5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 2.0882 - accuracy: 0.2668\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75892, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 16s 12ms/step - loss: 2.0747 - accuracy: 0.2719 - val_loss: 1.0642 - val_accuracy: 0.7589\n",
            "Epoch 2/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.8675 - accuracy: 0.7115\n",
            "Epoch 2: val_accuracy improved from 0.75892 to 0.88067, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8657 - accuracy: 0.7124 - val_loss: 0.4153 - val_accuracy: 0.8807\n",
            "Epoch 3/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.8216\n",
            "Epoch 3: val_accuracy improved from 0.88067 to 0.91500, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5462 - accuracy: 0.8222 - val_loss: 0.2932 - val_accuracy: 0.9150\n",
            "Epoch 4/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.8693\n",
            "Epoch 4: val_accuracy improved from 0.91500 to 0.93075, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.4140 - accuracy: 0.8695 - val_loss: 0.2300 - val_accuracy: 0.9308\n",
            "Epoch 5/100\n",
            "365/375 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.8921\n",
            "Epoch 5: val_accuracy improved from 0.93075 to 0.94233, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3413 - accuracy: 0.8918 - val_loss: 0.1935 - val_accuracy: 0.9423\n",
            "Epoch 6/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.9094\n",
            "Epoch 6: val_accuracy improved from 0.94233 to 0.95158, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2910 - accuracy: 0.9096 - val_loss: 0.1629 - val_accuracy: 0.9516\n",
            "Epoch 7/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.2561 - accuracy: 0.9208\n",
            "Epoch 7: val_accuracy improved from 0.95158 to 0.95700, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2557 - accuracy: 0.9209 - val_loss: 0.1483 - val_accuracy: 0.9570\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9260\n",
            "Epoch 8: val_accuracy improved from 0.95700 to 0.96050, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2339 - accuracy: 0.9260 - val_loss: 0.1342 - val_accuracy: 0.9605\n",
            "Epoch 9/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9334\n",
            "Epoch 9: val_accuracy improved from 0.96050 to 0.96067, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2134 - accuracy: 0.9334 - val_loss: 0.1309 - val_accuracy: 0.9607\n",
            "Epoch 10/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1939 - accuracy: 0.9391\n",
            "Epoch 10: val_accuracy improved from 0.96067 to 0.96592, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1937 - accuracy: 0.9392 - val_loss: 0.1139 - val_accuracy: 0.9659\n",
            "Epoch 11/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9442\n",
            "Epoch 11: val_accuracy improved from 0.96592 to 0.96825, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1812 - accuracy: 0.9440 - val_loss: 0.1054 - val_accuracy: 0.9682\n",
            "Epoch 12/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9447\n",
            "Epoch 12: val_accuracy improved from 0.96825 to 0.96975, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1755 - accuracy: 0.9447 - val_loss: 0.1018 - val_accuracy: 0.9697\n",
            "Epoch 13/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9490\n",
            "Epoch 13: val_accuracy improved from 0.96975 to 0.97092, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1660 - accuracy: 0.9488 - val_loss: 0.0965 - val_accuracy: 0.9709\n",
            "Epoch 14/100\n",
            "365/375 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9515\n",
            "Epoch 14: val_accuracy improved from 0.97092 to 0.97358, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1570 - accuracy: 0.9514 - val_loss: 0.0901 - val_accuracy: 0.9736\n",
            "Epoch 15/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9542\n",
            "Epoch 15: val_accuracy did not improve from 0.97358\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1500 - accuracy: 0.9542 - val_loss: 0.0880 - val_accuracy: 0.9732\n",
            "Epoch 16/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9558\n",
            "Epoch 16: val_accuracy improved from 0.97358 to 0.97442, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1439 - accuracy: 0.9557 - val_loss: 0.0844 - val_accuracy: 0.9744\n",
            "Epoch 17/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9582\n",
            "Epoch 17: val_accuracy improved from 0.97442 to 0.97650, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1359 - accuracy: 0.9582 - val_loss: 0.0799 - val_accuracy: 0.9765\n",
            "Epoch 18/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9585\n",
            "Epoch 18: val_accuracy improved from 0.97650 to 0.97675, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1323 - accuracy: 0.9587 - val_loss: 0.0772 - val_accuracy: 0.9768\n",
            "Epoch 19/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9613\n",
            "Epoch 19: val_accuracy improved from 0.97675 to 0.97708, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1251 - accuracy: 0.9613 - val_loss: 0.0739 - val_accuracy: 0.9771\n",
            "Epoch 20/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9615\n",
            "Epoch 20: val_accuracy improved from 0.97708 to 0.97742, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1231 - accuracy: 0.9615 - val_loss: 0.0735 - val_accuracy: 0.9774\n",
            "Epoch 21/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9627\n",
            "Epoch 21: val_accuracy improved from 0.97742 to 0.97867, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1203 - accuracy: 0.9626 - val_loss: 0.0712 - val_accuracy: 0.9787\n",
            "Epoch 22/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9644\n",
            "Epoch 22: val_accuracy did not improve from 0.97867\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1157 - accuracy: 0.9645 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
            "Epoch 23/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9647\n",
            "Epoch 23: val_accuracy improved from 0.97867 to 0.97967, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1130 - accuracy: 0.9648 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
            "Epoch 24/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9660\n",
            "Epoch 24: val_accuracy improved from 0.97967 to 0.98017, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1090 - accuracy: 0.9660 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
            "Epoch 25/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9664\n",
            "Epoch 25: val_accuracy improved from 0.98017 to 0.98092, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1061 - accuracy: 0.9666 - val_loss: 0.0653 - val_accuracy: 0.9809\n",
            "Epoch 26/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9667\n",
            "Epoch 26: val_accuracy improved from 0.98092 to 0.98142, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1063 - accuracy: 0.9667 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
            "Epoch 27/100\n",
            "365/375 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9693\n",
            "Epoch 27: val_accuracy did not improve from 0.98142\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1004 - accuracy: 0.9691 - val_loss: 0.0617 - val_accuracy: 0.9813\n",
            "Epoch 28/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9691\n",
            "Epoch 28: val_accuracy improved from 0.98142 to 0.98200, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0998 - accuracy: 0.9689 - val_loss: 0.0604 - val_accuracy: 0.9820\n",
            "Epoch 29/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9698\n",
            "Epoch 29: val_accuracy did not improve from 0.98200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0973 - accuracy: 0.9696 - val_loss: 0.0594 - val_accuracy: 0.9820\n",
            "Epoch 30/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9699\n",
            "Epoch 30: val_accuracy improved from 0.98200 to 0.98233, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0956 - accuracy: 0.9699 - val_loss: 0.0567 - val_accuracy: 0.9823\n",
            "Epoch 31/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9715\n",
            "Epoch 31: val_accuracy improved from 0.98233 to 0.98308, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0925 - accuracy: 0.9715 - val_loss: 0.0570 - val_accuracy: 0.9831\n",
            "Epoch 32/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9719\n",
            "Epoch 32: val_accuracy improved from 0.98308 to 0.98317, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
            "Epoch 33/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9721\n",
            "Epoch 33: val_accuracy improved from 0.98317 to 0.98392, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0897 - accuracy: 0.9721 - val_loss: 0.0544 - val_accuracy: 0.9839\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9722\n",
            "Epoch 34: val_accuracy improved from 0.98392 to 0.98400, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0875 - accuracy: 0.9722 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
            "Epoch 35/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9733\n",
            "Epoch 35: val_accuracy improved from 0.98400 to 0.98425, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0846 - accuracy: 0.9731 - val_loss: 0.0536 - val_accuracy: 0.9843\n",
            "Epoch 36/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9729\n",
            "Epoch 36: val_accuracy did not improve from 0.98425\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0860 - accuracy: 0.9729 - val_loss: 0.0541 - val_accuracy: 0.9837\n",
            "Epoch 37/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9734\n",
            "Epoch 37: val_accuracy improved from 0.98425 to 0.98442, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0863 - accuracy: 0.9735 - val_loss: 0.0545 - val_accuracy: 0.9844\n",
            "Epoch 38/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0813 - accuracy: 0.9742\n",
            "Epoch 38: val_accuracy improved from 0.98442 to 0.98483, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.0517 - val_accuracy: 0.9848\n",
            "Epoch 39/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9735\n",
            "Epoch 39: val_accuracy improved from 0.98483 to 0.98508, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0496 - val_accuracy: 0.9851\n",
            "Epoch 40/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9744\n",
            "Epoch 40: val_accuracy improved from 0.98508 to 0.98517, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0810 - accuracy: 0.9742 - val_loss: 0.0498 - val_accuracy: 0.9852\n",
            "Epoch 41/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9752\n",
            "Epoch 41: val_accuracy improved from 0.98517 to 0.98583, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0777 - accuracy: 0.9751 - val_loss: 0.0497 - val_accuracy: 0.9858\n",
            "Epoch 42/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9753\n",
            "Epoch 42: val_accuracy did not improve from 0.98583\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.0491 - val_accuracy: 0.9855\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9759\n",
            "Epoch 43: val_accuracy improved from 0.98583 to 0.98617, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0763 - accuracy: 0.9759 - val_loss: 0.0482 - val_accuracy: 0.9862\n",
            "Epoch 44/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9765\n",
            "Epoch 44: val_accuracy did not improve from 0.98617\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0737 - accuracy: 0.9764 - val_loss: 0.0479 - val_accuracy: 0.9859\n",
            "Epoch 45/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9762\n",
            "Epoch 45: val_accuracy improved from 0.98617 to 0.98642, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0752 - accuracy: 0.9764 - val_loss: 0.0470 - val_accuracy: 0.9864\n",
            "Epoch 46/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9770\n",
            "Epoch 46: val_accuracy did not improve from 0.98642\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0729 - accuracy: 0.9770 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
            "Epoch 47/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9778\n",
            "Epoch 47: val_accuracy did not improve from 0.98642\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.0477 - val_accuracy: 0.9861\n",
            "Epoch 48/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9771\n",
            "Epoch 48: val_accuracy improved from 0.98642 to 0.98708, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0729 - accuracy: 0.9771 - val_loss: 0.0455 - val_accuracy: 0.9871\n",
            "Epoch 49/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9783\n",
            "Epoch 49: val_accuracy did not improve from 0.98708\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0698 - accuracy: 0.9783 - val_loss: 0.0460 - val_accuracy: 0.9868\n",
            "Epoch 50/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9780\n",
            "Epoch 50: val_accuracy did not improve from 0.98708\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0713 - accuracy: 0.9780 - val_loss: 0.0457 - val_accuracy: 0.9866\n",
            "Epoch 51/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9781\n",
            "Epoch 51: val_accuracy did not improve from 0.98708\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0700 - accuracy: 0.9781 - val_loss: 0.0452 - val_accuracy: 0.9865\n",
            "Epoch 52/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9782\n",
            "Epoch 52: val_accuracy did not improve from 0.98708\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0688 - accuracy: 0.9782 - val_loss: 0.0448 - val_accuracy: 0.9870\n",
            "Epoch 53/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9790\n",
            "Epoch 53: val_accuracy improved from 0.98708 to 0.98733, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0443 - val_accuracy: 0.9873\n",
            "Epoch 54/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9784\n",
            "Epoch 54: val_accuracy did not improve from 0.98733\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.0443 - val_accuracy: 0.9873\n",
            "Epoch 55/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9788\n",
            "Epoch 55: val_accuracy improved from 0.98733 to 0.98750, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0653 - accuracy: 0.9787 - val_loss: 0.0441 - val_accuracy: 0.9875\n",
            "Epoch 56/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9794\n",
            "Epoch 56: val_accuracy did not improve from 0.98750\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0659 - accuracy: 0.9795 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
            "Epoch 57/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9796\n",
            "Epoch 57: val_accuracy did not improve from 0.98750\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
            "Epoch 58/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9795\n",
            "Epoch 58: val_accuracy did not improve from 0.98750\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0645 - accuracy: 0.9796 - val_loss: 0.0430 - val_accuracy: 0.9875\n",
            "Epoch 59/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9808\n",
            "Epoch 59: val_accuracy improved from 0.98750 to 0.98758, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.0425 - val_accuracy: 0.9876\n",
            "Epoch 60/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9805\n",
            "Epoch 60: val_accuracy did not improve from 0.98758\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.0426 - val_accuracy: 0.9873\n",
            "Epoch 61/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9803\n",
            "Epoch 61: val_accuracy improved from 0.98758 to 0.98775, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
            "Epoch 62/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9814\n",
            "Epoch 62: val_accuracy improved from 0.98775 to 0.98833, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0587 - accuracy: 0.9815 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
            "Epoch 63/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9809\n",
            "Epoch 63: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.0417 - val_accuracy: 0.9880\n",
            "Epoch 64/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9815\n",
            "Epoch 64: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0595 - accuracy: 0.9817 - val_loss: 0.0415 - val_accuracy: 0.9880\n",
            "Epoch 65/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9808\n",
            "Epoch 65: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.0426 - val_accuracy: 0.9877\n",
            "Epoch 66/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9814\n",
            "Epoch 66: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.0410 - val_accuracy: 0.9877\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9817\n",
            "Epoch 67: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0593 - accuracy: 0.9817 - val_loss: 0.0410 - val_accuracy: 0.9881\n",
            "Epoch 68/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9817\n",
            "Epoch 68: val_accuracy did not improve from 0.98833\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 0.0404 - val_accuracy: 0.9881\n",
            "Epoch 69/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9814\n",
            "Epoch 69: val_accuracy improved from 0.98833 to 0.98842, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 0.0404 - val_accuracy: 0.9884\n",
            "Epoch 70/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9815\n",
            "Epoch 70: val_accuracy did not improve from 0.98842\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0404 - val_accuracy: 0.9879\n",
            "Epoch 71/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9825\n",
            "Epoch 71: val_accuracy improved from 0.98842 to 0.98917, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0394 - val_accuracy: 0.9892\n",
            "Epoch 72/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9820\n",
            "Epoch 72: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.0399 - val_accuracy: 0.9886\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9814\n",
            "Epoch 73: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
            "Epoch 74/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9819\n",
            "Epoch 74: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0561 - accuracy: 0.9820 - val_loss: 0.0394 - val_accuracy: 0.9885\n",
            "Epoch 75/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9819\n",
            "Epoch 75: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.0401 - val_accuracy: 0.9886\n",
            "Epoch 76/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9826\n",
            "Epoch 76: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0391 - val_accuracy: 0.9887\n",
            "Epoch 77/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9833\n",
            "Epoch 77: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.0391 - val_accuracy: 0.9883\n",
            "Epoch 78/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9829\n",
            "Epoch 78: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.0393 - val_accuracy: 0.9883\n",
            "Epoch 79/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9823\n",
            "Epoch 79: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.0383 - val_accuracy: 0.9887\n",
            "Epoch 80/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9835\n",
            "Epoch 80: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0526 - accuracy: 0.9835 - val_loss: 0.0385 - val_accuracy: 0.9886\n",
            "Epoch 81/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9832\n",
            "Epoch 81: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 0.0378 - val_accuracy: 0.9892\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9830\n",
            "Epoch 82: val_accuracy did not improve from 0.98917\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 0.0383 - val_accuracy: 0.9890\n",
            "Epoch 83/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9838\n",
            "Epoch 83: val_accuracy improved from 0.98917 to 0.98942, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
            "Epoch 84/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9840\n",
            "Epoch 84: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 0.0383 - val_accuracy: 0.9889\n",
            "Epoch 85/100\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9827\n",
            "Epoch 85: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.0372 - val_accuracy: 0.9892\n",
            "Epoch 86/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9835\n",
            "Epoch 86: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
            "Epoch 87/100\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9830\n",
            "Epoch 87: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.0382 - val_accuracy: 0.9888\n",
            "Epoch 88/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9840\n",
            "Epoch 88: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 0.0382 - val_accuracy: 0.9890\n",
            "Epoch 89/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9840\n",
            "Epoch 89: val_accuracy did not improve from 0.98942\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
            "Epoch 90/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9852\n",
            "Epoch 90: val_accuracy improved from 0.98942 to 0.98958, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
            "Epoch 91/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9846\n",
            "Epoch 91: val_accuracy improved from 0.98958 to 0.98967, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0369 - val_accuracy: 0.9897\n",
            "Epoch 92/100\n",
            "367/375 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9846\n",
            "Epoch 92: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.0364 - val_accuracy: 0.9893\n",
            "Epoch 93/100\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9837\n",
            "Epoch 93: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.0366 - val_accuracy: 0.9894\n",
            "Epoch 94/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9841\n",
            "Epoch 94: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.0360 - val_accuracy: 0.9897\n",
            "Epoch 95/100\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9851\n",
            "Epoch 95: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.0370 - val_accuracy: 0.9894\n",
            "Epoch 96/100\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9854\n",
            "Epoch 96: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.0358 - val_accuracy: 0.9897\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9850\n",
            "Epoch 97: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.0365 - val_accuracy: 0.9893\n",
            "Epoch 98/100\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9851\n",
            "Epoch 98: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0366 - val_accuracy: 0.9897\n",
            "Epoch 99/100\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9848\n",
            "Epoch 99: val_accuracy did not improve from 0.98967\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.0358 - val_accuracy: 0.9892\n",
            "Epoch 100/100\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9849\n",
            "Epoch 100: val_accuracy improved from 0.98967 to 0.98975, saving model to mnist/try02.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 0.0358 - val_accuracy: 0.9898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model_1.evaluate(test_imgs, test_labels)\n",
        "print(\"\\n테스트 정확도: %.4f\" %(result)[1])"
      ],
      "metadata": {
        "id": "A4f_4uKMk9gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea465f0-6db4-4431-d8e5-c58ad9c8ce78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9910\n",
            "\n",
            "테스트 정확도: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('mnist/try02.h5')\n",
        "result_loaded = loaded_model.evaluate(test_imgs, test_labels)\n",
        "print(\"\\n불러온 모델 테스트 정확도: %.4f\" %(result_loaded)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWt1g385nipq",
        "outputId": "be402ce9-e13a-4c5b-d1d0-7a11719bd3cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9910\n",
            "\n",
            "불러온 모델 테스트 정확도: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = hist_1.history['accuracy']\n",
        "val_acc = hist_1.history['val_accuracy']\n",
        "loss = hist_1.history['loss']\n",
        "val_loss = hist_1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.figure(figsize=(8, 12))\n",
        "ax1=plt.subplot(2, 1, 1)\n",
        "ax2=plt.subplot(2, 1, 2)\n",
        "ax1.plot(epochs, acc, 'bo', label='Trainig acc')\n",
        "ax1.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "ax1.set_title(\"Training and Validation accuracy\")\n",
        "ax1.legend()\n",
        "ax2.plot(epochs, loss, 'bo', label='Traning loss')\n",
        "ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "ax2.set_title(\"Training and Validation loss\")\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFOaiWO_sRfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "6a72d5bb-ede4-4a78-9f22-0b58426f8dd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([['CNN', 'model_1', '32(relu/drop0.2)-64(relu/drop0.2)-128(relu/drop0.5)-Flatten-64(sigmoid)-10(softmax)]', 'SGD', 100, 128, 0.2, 'es/mc', \n",
        "                    \"%.4f\"%(result)[1], \"%.4f\"%(result_loaded)[1], \"%.4f\"%(result)[0], \"%.4f\"%(result_loaded)[0]]],\n",
        "                  columns=['모델', 'Name', 'Structure', 'Optimizer', 'epochs', 'batch_size', 'validation_split', 'callback', 'Accuracy', 'MC_Accuracy', 'Loss', 'MC_Loss'])"
      ],
      "metadata": {
        "id": "YU51jOGcl7DL"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}