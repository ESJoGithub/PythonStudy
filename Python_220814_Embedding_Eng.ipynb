{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aca2805",
   "metadata": {},
   "source": [
    "# 쿠텐베르크 동화를 활용한 영단어 Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6239150",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a39882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3159826",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://www.gutenberg.org/files/2591/2591-0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c28ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "grimm = res.text[2801:530661]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760b4d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grimm = re.sub(r'[^a-zA-Z\\. ]', ' ', grimm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c64a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = grimm.split(\". \")              # 문장 단위로 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [s.split() for s in sentences]     # 단어 단위로 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8787968e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SECOND',\n",
       " 'STORY',\n",
       " 'THE',\n",
       " 'SALAD',\n",
       " 'THE',\n",
       " 'STORY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'YOUTH',\n",
       " 'WHO',\n",
       " 'WENT',\n",
       " 'FORTH',\n",
       " 'TO',\n",
       " 'LEARN',\n",
       " 'WHAT',\n",
       " 'FEAR',\n",
       " 'WAS',\n",
       " 'KING',\n",
       " 'GRISLY',\n",
       " 'BEARD',\n",
       " 'IRON',\n",
       " 'HANS',\n",
       " 'CAT',\n",
       " 'SKIN',\n",
       " 'SNOW',\n",
       " 'WHITE',\n",
       " 'AND',\n",
       " 'ROSE',\n",
       " 'RED',\n",
       " 'THE',\n",
       " 'BROTHERS',\n",
       " 'GRIMM',\n",
       " 'FAIRY',\n",
       " 'TALES',\n",
       " 'THE',\n",
       " 'GOLDEN',\n",
       " 'BIRD',\n",
       " 'A',\n",
       " 'certain',\n",
       " 'king',\n",
       " 'had',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'garden',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " 'stood',\n",
       " 'a',\n",
       " 'tree',\n",
       " 'which',\n",
       " 'bore',\n",
       " 'golden',\n",
       " 'apples']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a783dfe",
   "metadata": {},
   "source": [
    "### Word2Vec 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1445bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d27b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(data,               # 리스트 형태의 데이터\n",
    "                 sg=1,               # 0: CBOW, 1: skip-gram\n",
    "                 vector_size=100,    # 벡터 크기 하나의 단어를 몇 차원 벡터로 표현할 것인가\n",
    "                 window=3,           # 고려할 앞뒤 범위(앞 뒤 3 단어)\n",
    "                 min_count=3,        # 사용할 단어의 최소 빈도(3회 이하 단어 무시)\n",
    "                 workers=4           # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f1157",
   "metadata": {},
   "source": [
    "#### 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff054a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35fc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603e128",
   "metadata": {},
   "source": [
    "#### wv 메소드로 유사어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f179d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13470188,  0.11796378, -0.06052293,  0.13504401,  0.01958002,\n",
       "       -0.31074673,  0.11877873,  0.5310646 , -0.21852227, -0.2580635 ,\n",
       "        0.0372058 , -0.32491234,  0.02511626,  0.109215  ,  0.14125998,\n",
       "       -0.21415263,  0.03035061, -0.11118113, -0.1481159 , -0.23580956,\n",
       "        0.22472575,  0.1551313 ,  0.17465192, -0.18112889,  0.01991536,\n",
       "       -0.01570466,  0.03458815, -0.05552115, -0.14782451, -0.08897363,\n",
       "        0.07145429, -0.1360997 ,  0.12224001, -0.16139035, -0.16858649,\n",
       "        0.1852571 ,  0.03969387, -0.043217  , -0.06977359, -0.11906592,\n",
       "        0.09833706, -0.09055311, -0.03794726,  0.07245405, -0.06045794,\n",
       "        0.02491899, -0.1353533 , -0.09347339,  0.18845795,  0.05946556,\n",
       "        0.0934922 , -0.0616981 , -0.07652557, -0.10545052,  0.14572676,\n",
       "        0.10431336,  0.1188615 ,  0.020956  , -0.20838934,  0.01984456,\n",
       "       -0.06827766,  0.07428323,  0.14685601, -0.19489628, -0.2774837 ,\n",
       "        0.10785498,  0.05206594,  0.37525922, -0.25717565,  0.27155256,\n",
       "        0.00367793,  0.02691364,  0.22174501, -0.09458115,  0.29369956,\n",
       "       -0.05902104,  0.05276601, -0.03697764, -0.05148019,  0.04635689,\n",
       "       -0.24668996,  0.03091715, -0.20428327,  0.23841476, -0.14258818,\n",
       "       -0.03857109,  0.04013821,  0.20406853,  0.12715004, -0.00635017,\n",
       "        0.11013772,  0.07164218, -0.06513197,  0.12791002,  0.1964316 ,\n",
       "        0.21038866,  0.00116407, -0.1923988 , -0.11397287, -0.18314485],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"princess\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc3aed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"princess\", \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc940a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('palace', 0.98224276304245),\n",
       " ('fox', 0.9820863008499146),\n",
       " ('dwarf', 0.9820170402526855),\n",
       " ('wedding', 0.9807780981063843),\n",
       " ('boy', 0.9805260896682739),\n",
       " ('prince', 0.9786450266838074),\n",
       " ('huntsmen', 0.9785482287406921),\n",
       " ('same', 0.9785082340240479),\n",
       " ('fairy', 0.9777272939682007),\n",
       " ('dog', 0.9771775007247925)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('princess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9b3994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9616175293922424),\n",
       " ('bird', 0.9612706899642944),\n",
       " ('eldest', 0.9607287049293518),\n",
       " ('prince', 0.9594089388847351),\n",
       " ('frog', 0.9572567939758301),\n",
       " ('fisherman', 0.9571784734725952),\n",
       " ('gardener', 0.9562231302261353),\n",
       " ('boy', 0.955575704574585),\n",
       " ('bride', 0.9554721713066101),\n",
       " ('shepherd', 0.9550653100013733)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['man', 'princess'], negative=['woman'])\n",
    "# man + princess - woman prince를 기대값으로 하지만 학습량이 적어서 정확도 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac083acb",
   "metadata": {},
   "source": [
    "### Keras에서 Embedding하여 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c4fc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92d9170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2446, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape # 단어 수, 벡터 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3866713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS, EMB_DIM = model.wv.vectors.shape\n",
    "emb = Embedding(input_dim=NUM_WORDS, output_dim=EMB_DIM,\n",
    "               trainable=False, weights=[model.wv.vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07674b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         244600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,600\n",
      "Trainable params: 0\n",
      "Non-trainable params: 244,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = Sequential()\n",
    "net.add(emb)\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a0e38",
   "metadata": {},
   "source": [
    "#### gensim 과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6dfe217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 166ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.13470188,  0.11796378, -0.06052293,  0.13504401,  0.01958002,\n",
       "        -0.31074673,  0.11877873,  0.5310646 , -0.21852227, -0.2580635 ,\n",
       "         0.0372058 , -0.32491234,  0.02511626,  0.109215  ,  0.14125998,\n",
       "        -0.21415263,  0.03035061, -0.11118113, -0.1481159 , -0.23580956,\n",
       "         0.22472575,  0.1551313 ,  0.17465192, -0.18112889,  0.01991536,\n",
       "        -0.01570466,  0.03458815, -0.05552115, -0.14782451, -0.08897363,\n",
       "         0.07145429, -0.1360997 ,  0.12224001, -0.16139035, -0.16858649,\n",
       "         0.1852571 ,  0.03969387, -0.043217  , -0.06977359, -0.11906592,\n",
       "         0.09833706, -0.09055311, -0.03794726,  0.07245405, -0.06045794,\n",
       "         0.02491899, -0.1353533 , -0.09347339,  0.18845795,  0.05946556,\n",
       "         0.0934922 , -0.0616981 , -0.07652557, -0.10545052,  0.14572676,\n",
       "         0.10431336,  0.1188615 ,  0.020956  , -0.20838934,  0.01984456,\n",
       "        -0.06827766,  0.07428323,  0.14685601, -0.19489628, -0.2774837 ,\n",
       "         0.10785498,  0.05206594,  0.37525922, -0.25717565,  0.27155256,\n",
       "         0.00367793,  0.02691364,  0.22174501, -0.09458115,  0.29369956,\n",
       "        -0.05902104,  0.05276601, -0.03697764, -0.05148019,  0.04635689,\n",
       "        -0.24668996,  0.03091715, -0.20428327,  0.23841476, -0.14258818,\n",
       "        -0.03857109,  0.04013821,  0.20406853,  0.12715004, -0.00635017,\n",
       "         0.11013772,  0.07164218, -0.06513197,  0.12791002,  0.1964316 ,\n",
       "         0.21038866,  0.00116407, -0.1923988 , -0.11397287, -0.18314485]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = model.wv.index_to_key.index(\"princess\")\n",
    "net.predict([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6881c08",
   "metadata": {},
   "source": [
    "#### 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b99adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9467dc8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e03b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ea92f",
   "metadata": {},
   "source": [
    "### 사전학습 Word2Vec 가져오기\n",
    "---\n",
    "구글 사전 훈련 word2vec 호출해서 사용하기\n",
    "\n",
    "모델 다운로드 경로 : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin 파일 경로', binary=True)\n",
    "\n",
    "wv.similarity()에 두 단어를 넘겨주면 코사인 유사도를 구할 수 있다.\n",
    "wv.most_similar()에 단어를 넘겨주면 가장 유사한 단어를 추출할 수 있다.\n",
    ".wv_most_similar() 에 positive와 negative라는 옵션을 넘겨줄 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
